Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=64000, mem_mib=61036, disk_mb=1000, disk_mib=954, cpus_per_task=12
Select jobs to execute...

[Thu May 23 14:44:58 2024]
rule RNA_Plot_sex_DEG_volcano_GO:
    input: results/processed_data/mm10/RNA_all_SexDEGs.Robj, results/processed_data/mm10/RNA_samplesheet.csv
    output: results/graphs/mm10/PDF/RNA_sex_DEG_volcano.pdf, results/graphs/mm10/PNG/RNA_sex_DEG_volcano.png
    jobid: 0
    reason: Forced execution
    resources: mem_mb=64000, mem_mib=61036, disk_mb=1000, disk_mib=954, tmpdir=/tmp, cpus_per_task=12

Rscript --vanilla /work/user/istevant/project/SupportingCRE/.snakemake/scripts/tmp9bto97wr.RNA_plot_sex_volcano_GO.R
Warning message:
replacing previous import ‘S4Arrays::makeNindexFromArrayViewport’ by ‘DelayedArray::makeNindexFromArrayViewport’ when loading ‘SummarizedExperiment’ 
/usr/bin/bash: line 1: 2538047 Killed                  Rscript --vanilla /work/user/istevant/project/SupportingCRE/.snakemake/scripts/tmp9bto97wr.RNA_plot_sex_volcano_GO.R
Not cleaning up /work/user/istevant/project/SupportingCRE/.snakemake/scripts/tmp9bto97wr.RNA_plot_sex_volcano_GO.R
[Thu May 23 14:45:32 2024]
Error in rule RNA_Plot_sex_DEG_volcano_GO:
    jobid: 0
    input: results/processed_data/mm10/RNA_all_SexDEGs.Robj, results/processed_data/mm10/RNA_samplesheet.csv
    output: results/graphs/mm10/PDF/RNA_sex_DEG_volcano.pdf, results/graphs/mm10/PNG/RNA_sex_DEG_volcano.png

RuleException:
CalledProcessError in file /work/user/istevant/project/SupportingCRE/Snakefile, line 183:
Command 'set -euo pipefail;  Rscript --vanilla /work/user/istevant/project/SupportingCRE/.snakemake/scripts/tmp9bto97wr.RNA_plot_sex_volcano_GO.R' returned non-zero exit status 137.
  File "/work/user/istevant/project/SupportingCRE/Snakefile", line 183, in __rule_RNA_Plot_sex_DEG_volcano_GO
  File "/work/user/istevant/project/SupportingCRE/.conda/envs/SupportingCRE/lib/python3.9/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
slurmstepd: error: Detected 2 oom_kill events in StepId=8049474.batch. Some of the step tasks have been OOM Killed.
